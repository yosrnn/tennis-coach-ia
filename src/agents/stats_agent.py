# =============================================================
# stats_agent.py ‚Äî Agent d'analyse statistique
# =============================================================
# R√¥le : r√©pond aux questions pr√©cises sur des chiffres
# en interrogeant directement le CSV avec Pandas.
# Exemple : "combien d'aces Djokovic en 2023 ?"
#
# Diff√©rence avec rag_agent :
#   rag_agent   ‚Üí questions de sens, contexte, style de jeu
#   stats_agent ‚Üí questions pr√©cises, chiffres, classements
# =============================================================

import os
import pandas as pd
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, SystemMessage

load_dotenv()

# --- Config ---
DATA_PATH = "/Users/yosrnoureddine/tennis-coach-ia/data/processed/atp_clean.csv"

# --- Initialisation ---
df = pd.read_csv(DATA_PATH)
llm = ChatGroq(
    model="llama-3.3-70b-versatile",
    api_key=os.getenv("GROQ_API_KEY")
)

def stats_agent(question: str) -> str:
    # 1. Donne au LLM le sch√©ma du CSV pour qu'il g√©n√®re le bon code Pandas
    schema = """
    Colonnes disponibles :
    - tourney_name, surface, tourney_date, round
    - winner_name, loser_name, score
    - winner_rank, loser_rank
    - w_ace, w_df, w_1stIn, w_1stWon, w_2ndWon, w_bpSaved, w_bpFaced
    - l_ace, l_df, l_1stIn, l_1stWon, l_2ndWon, l_bpSaved, l_bpFaced

    Notes :
    - tourney_date est au format YYYYMMDD (ex: 20230101)
    - w_ = stats du vainqueur, l_ = stats du perdant
    """

    # 2. Demande au LLM de g√©n√©rer du code Pandas
    messages = [
        SystemMessage(content=f"""Tu es un expert en analyse de donn√©es tennis.
Tu g√©n√®res du code Pandas pour r√©pondre √† des questions sur un DataFrame appel√© 'df'.
R√©ponds UNIQUEMENT avec du code Python valide, sans explication, sans markdown.
{schema}"""),
        HumanMessage(content=f"Question : {question}\nG√©n√®re le code Pandas et stocke le r√©sultat dans une variable 'result'.")
    ]

    code_response = llm.invoke(messages)

    # 3. Nettoie le code (enl√®ve les backticks markdown)
    code = code_response.content.strip()
    code = code.replace("```python", "").replace("```", "").strip()

    # 4. Ex√©cute le code g√©n√©r√©
    try:
        local_vars = {"df": df, "pd": pd}
        exec(code, local_vars)
        result = local_vars.get("result", "Aucun r√©sultat")
    except Exception as e:
        return f"Erreur d'ex√©cution : {e}\nCode g√©n√©r√© : {code}"

    # 5. Demande au LLM de formuler une r√©ponse lisible
    messages2 = [
        SystemMessage(content="Tu es Coach IA. Formule une r√©ponse claire et concise bas√©e sur ce r√©sultat de donn√©es tennis."),
        HumanMessage(content=f"Question : {question}\nR√©sultat des donn√©es : {result}")
    ]

    final_response = llm.invoke(messages2)
    return final_response.content

if __name__ == "__main__":
    question = "How many aces did Djokovic make in 2023?"
    print(f"üéæ Question : {question}\n")
    print(f"ü§ñ R√©ponse :\n{stats_agent(question)}")